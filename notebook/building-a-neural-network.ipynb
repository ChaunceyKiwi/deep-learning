{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - The general methodology to build a Neural Network\n",
    "\n",
    "1. Define the neural network structure (# of input units, # of hidden units, etc)\n",
    "2. Initialize the model's parameters\n",
    "3. Loop\n",
    "    - Forward propagation\n",
    "    - Compute loss\n",
    "    - Backward propagation to get the gradients\n",
    "    - Update parameters (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - General Idea of Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Neural Network Model\n",
    "\n",
    "<img src=\"./img/neural_network_model.png\" style=\"width:540px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Forward Propagation\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "\n",
    "$$z^{[1](i)} = W^{[1]}x^{(i)} + b^{[1](i)}$$\n",
    "\n",
    "$$a^{[1](i)} = tanh(z^{[1](i)})$$\n",
    "\n",
    "$$z^{[2](i)} = W^{[2]}a^{[1](i)} + b^{[2](i)}$$\n",
    "\n",
    "$$\\hat{y}^{(i)} = a^{[2](i)} = \\sigma(z^{[2](i)})$$\n",
    "\n",
    "$$y^{(i)}_{prediction}= \n",
    "\\begin{cases}\n",
    "    1, & \\text{if } \\hat{y}^{(i)} > 0.5 \\\\\n",
    "    0, & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Cost Function\n",
    "\n",
    "$$J = - \\frac{1}{m} \\sum_{i = 0}^{m} \\large{(} y^{(i)}\\log(a^{[2] (i)}) + (1-y^{(i)})\\log(1- a^{[2] (i)}){)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Backpropagation\n",
    "\n",
    "<img src=\"./img/grad_summary.png\" style=\"width:600px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Update parameter\n",
    "\n",
    "General gradient descent rule: $\\theta = \\theta - \\alpha \\frac{\\partial J}{\\partial \\theta}$, where $\\alpha$ is the learning rate and $\\theta$ represents a parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Further explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Backpropagation\n",
    "\n",
    "Calculateing the partial derivate of the error with respect to weight $W_{ij}$ is done using the chain rule twice:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_{ij}} = \\frac{\\partial J}{\\partial o_j} \\frac{\\partial o_j}{\\partial net_j} \\frac{\\partial net_j}{\\partial w_{ij}}$$\n",
    "\n",
    "$J$ is cost function.\n",
    "\n",
    "For each neuron $j$, its output $o_{j}$ is defined as \n",
    "$$o_j = \\varphi(net_j) = \\varphi(\\sum_{k=1}^{n}w_{kj}o_k)$$\n",
    "The activation function $\\varphi$ is non-linear and differentiable. Common activation function includes sigmoid and TanH.\n",
    "\n",
    "The input $net_j$ to a neuron is the weighted sum of output $o_k$ of previous neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third factor of $\\frac{\\partial J}{\\partial w_{ij}}$:\n",
    "\n",
    "$$\\frac{\\partial net_j}{\\partial w_{ij}} = \\frac{\\partial}{\\partial w_{ij}} \\Bigg(\\sum_{k=1}^{n}w_{kj}o_k\\Bigg) = \\frac{\\partial}{\\partial w_{ij}} w_{ij}o_i = o_i $$\n",
    "\n",
    "If the neuron is the first layer after the input layer, $o_i$ is just $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second factor of $\\frac{\\partial J}{\\partial w_{ij}}$:\n",
    "\n",
    "$$\\frac{\\partial o_j}{\\partial net_j} = \\frac{\\partial}{\\partial net_j} \\varphi(net_j) = \\varphi'(net_j)$$\n",
    "\n",
    "The derivative of the putput of neuron $j$ with respect to its input is simpy the partial derivative of the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first factor of $\\frac{\\partial J}{\\partial w_{ij}}$:\n",
    "When the neuron is in the output layer, since $o_j = y$\n",
    "$$\\frac{\\partial J}{\\partial o_j} = \\frac{\\partial J(y)}{\\partial y} = J'(y)$$\n",
    "\n",
    "When $j$ is in an arbitary inner layer of the network, finding the derivative $J$ with respect to $o_j$ is less obvious. \n",
    "\n",
    "Considering $J$ as a function of the inputs of all neurons $L = u,v, ..., w$ receiving from neuron $j$\n",
    "\n",
    "$$\\frac{\\partial J(o_j)}{\\partial o_j} = \\frac{\\partial J(net_u, net_v, ..., net_w)}{\\partial o_j}\n",
    "= \\sum_{l \\in L} \\Bigg(\\frac{\\partial J}{\\partial net_l} \\frac{\\partial net_l}{\\partial o_j}\\Bigg)\n",
    "= \\sum_{l \\in L} \\Bigg(\\frac{\\partial J}{\\partial o_l} \\frac{\\partial o_l}{\\partial net_l} \\frac{\\partial net_l}{\\partial o_j}\\Bigg)\n",
    "= \\sum_{l \\in L} \\Bigg(\\frac{\\partial J}{\\partial o_l} \\frac{\\partial o_l}{\\partial net_l}w_{jl}\\Bigg)$$\n",
    "\n",
    "Therefore, the derivation with respect to $o_j$ can be calculated if all the derivatives with respect to the outputs $o_l$ of the next layer are known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial w_{ij}} = \\delta_j o_i$$\n",
    "with\n",
    "$$\\delta_j = \\frac{\\partial J}{\\partial o_j}\\frac{\\partial o_j}{\\partial net_j} =\n",
    "\\begin{cases}\n",
    "    J'(o_j) \\varphi'(net_j), & \\text{if $j$ is an output neuron} \\\\\n",
    "    (\\sum_{l \\in L}w_{jl}\\delta_l)\\varphi'(net_j), & \\text{if $j$ is an inner neuron}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abount summary of gradient descent in 2.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmid is used in output layer. Thus $\\varphi(z) = \\frac{1}{1 + e^{-z}}$, which has a convenient derivative of \n",
    "$$\\frac{d\\varphi}{dz}(z) = \\varphi(z)(1-\\varphi(z))$$\n",
    "\n",
    "Thus\n",
    "\n",
    "$$dz^{[2]} = J'(o_j) \\varphi'(net_j) = (-yloga + (1-y)log(1-a))'(a)(1-a) = \n",
    "(\\frac{-y}{a} + \\frac{1-y}{1-a})(a)(1-a) = a^{[2]} - y$$ \n",
    "\n",
    "$$dz^{[1]} = (\\sum_{l \\in L}w_{jl}\\delta_l)\\varphi'(net_j) = W^{[2]T}dz^{[2]}g^{[1]'}(z^[1])$$\n",
    "\n",
    "From\n",
    "\n",
    "$$z^{[2](i)} = W^{[2]}a^{[1](i)} + b^{[2](i)}$$\n",
    "\n",
    "$$z^{[1](i)} = W^{[1]}x^{(i)} + b^{[1](i)}$$\n",
    "\n",
    "we know that\n",
    "\n",
    "$$dW^{[2]} = dz^{[2]}a^{[1]T}$$\n",
    "\n",
    "$$db^{[2]} = dz^{[2]}$$\n",
    "\n",
    "$$dW^{[1]} = dz^{[1]}x^{T}$$\n",
    "\n",
    "$$db^{[1]} = dz^{[1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "- Coursera Deep Learning, Andrew Ng, https://www.coursera.org/learn/neural-networks-deep-learning/programming/wRuwL/planar-data-classification-with-a-hidden-layer\n",
    "- Wikipedia contributors, \"Backpropagation,\" Wikipedia, The Free Encyclopedia, https://en.wikipedia.org/w/index.php?title=Backpropagation&oldid=871032328 (accessed December 1, 2018).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
